---
article_num:         208
layout:              post
type:                classic
title:               Highlight 2022
subtitle:            >
    My tech journey at Datadog as a software engineer and some side-projects
    in my free time.

lang:                en
date:                2022-12-23 17:46:31 +0100
categories:          [review]
tags:                [review, career]
ads_tags:            []
comments:            true
excerpt:             >
    My tech journey at Datadog as a software engineer in 2022 and some
    side-projects in my free time.

image:               /assets/bg-kelly-sikkema--64OzuZ8ThE-unsplash.jpg
cover:               /assets/bg-kelly-sikkema--64OzuZ8ThE-unsplash.jpg
article_header:
  type:              overlay
  theme:             dark
  background_color:  "#203028"
  background_image:
    gradient:        "linear-gradient(135deg, rgba(0, 0, 0, .6), rgba(0, 0, 0, .4))"
wechat:              false
---

## Introduction

Writing an article for an annual review becomes a tradition for me. After
writing for 6 consecutive years
([link](/en/categories/review/)), I decided to continue this year, to share with
you my journey in the tech industry, as a software engineer at Datadog and as an
explorer for other side-projects during my free time. Hopefully, they will let
you learn something or inspire you to create your story. Now, let's get started!

## Datadog

I joined Datadog at the end of 2019 as a software engineer working for the Event
Platform. This year, I was part of the automation team, which improves the site
reliability, reduces toil and facilitates engineer's daily work. My
contributions are around automation development and can be summarized in 4 parts:

* **Operation workflows.** Developing operation-related workflows which create
  or delete complex data pipelines or data stores. Before these workflows, we
  had to create or delete them manually, which was complex and time-consuming.
  By using workflows, we can achieve these actions in an easier way. They
  excel the platform's goals, such as data-store migration, incident
  remediation, data isolation improvement, and more. The operation workflows are
  developed using workflow engine [Temporal](https://temporal.io), you can see
  the case study [Temporal at Datadog by Kevin
  Devroede](https://temporal.io/case-studies/how-datadog-ensures-database-reliability-with-temporal)
  or the YouTube video [Temporal at Datadog by Jacob
  LeGrone](https://youtu.be/LxgkAoTSI8Q) to learn more.
* **Automation safety.** To ensure the automation can be performed safely
  without any customer impact, I
  also developed a verification process, which collects data in different
  dimensions and makes decisions based on business requirements. Thanks to this
  framework, we were able to see the state of the whole system in one
  place and perform operations with great confidence. It allowed the storage
  team to migrate all data stores from the old system to the new one which
  changed the pipeline architecture and the internal engine. The framework is
  also extensible: several engineers contributed additional deciders which make
  additional decisions.
* **Automation utilities.** Writing workflows can be very complex. We need
  different utilities to faciliate the development. This year, I developed a
  RESTful API client in Go, some frontend integration for workflows, a custom
  release mechanism, an analytics helper, some workflow templates, a Go package for
  configuration manipulation, and some other tools to faciliate the development
  for other
  engineers. A good example was that a junior was able to create a new workflow
  in less than 2 days during his hackathon project, which was pretty cool!
* **Other works.** There are also other contributions made in different aspects:
  cross-team collobarations, being an interviewer, being interrupt handler (IH),
  being on call, participate to RFC review and code review, and more.

Compared to last year, the main difference of my contributions is that I was
more involved in system design and team collaboration. TODO add more details.
For the coming year, I want to support the growth of the platform and other
storage systems by bringing more solutions related to SRE and automation. To
achieve this, there are improvements to do for system understanding, software
design, delivery speed, team colloborations, communication, and more.

## Blog

This year I put less energy in blog writing and focused more on my daily work. The
blog was mainly about system design (5 posts), but I also wrote some
articles related to workflow automation, documentation, and API design. These
posts are related to what I learned from my work since I had the chance to
develop a new automation solution for internal usage. Here are three articles
that I want to share with you:

* [Internal Working of the GitLab API Go Client](/en/go-gitlab/)
* [Internal Working of Temporal Java Service Client](/en/temporal-java-service-client/)
* [Internal Structure Of Elasticsearch Java High-Level REST Client](/en/elasticsearch-hlrc/)

To improve the user experience, I developed several new features for
my blog: rebranding the home page, adding the search capability, and introducing
the post id. This wasnâ€™t easy because each feature requires some work: for the
home page, I need to get some inspiration from other websites, modify the Jekyll
template and adjust some CSS. As for the search feature, I needed to set up a
search service with Java and Elasticsearch, and I also needed to integrate with
Datadog. But I loved this site project as it is useful for other developers and
helped me to gain more experience in development and operations.

Whatâ€™s next? Last year I was too ambitious so this year I want to keep it simple
ðŸ˜€ I hope that I can keep a stable delivery cadence, e.g. having 17 posts next
year (1 post every 3 weeks) and with focus on one or two main topics, e.g.
microservices, automation, or system design. Also, I want to share these posts
to Medium so that more people can subscribe easily.

## Finance

[Finance toolkit](https://github.com/mincong-h/finance-toolkit/) is a small
library helping you to understand your personal financial situation by
extracting, transforming, and aggregating transactions from different companies
into a single place. The companies supported are: BNP Paribas, Boursorama,
Revolut, and some others. It generates CSV files that can be used for data
visualization. It was created in 2019 and written in Python by [Jingwen
Zheng](https://github.com/jingwen-z) and
I, with some help from [MickaÃ«l Schoentgen](https://github.com/BoboTiG). This
year, we improved the Revolut
integration, added support for multiple currencies (EUR, USD), brought some
technical improvements (e.g. logging, testing, error handling), and open-sourced
the project on GitHub. This tool helped us increase our savings by 7.3 times
over the last 4 years.

## Conclusion

What did we talk in this article? Take notes from introduction again.
Interested to know more? You can subscribe to [the feed of my blog](/feed.xml), follow me
on [Twitter](https://twitter.com/mincong_h) or
[GitHub](https://github.com/mincong-h/). Hope you enjoy this article, see you the next time!

## References
